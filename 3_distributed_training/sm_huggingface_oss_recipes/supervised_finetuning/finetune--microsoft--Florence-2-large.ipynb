{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60b91a9-7d9c-4c45-be0f-5a224581f644",
   "metadata": {},
   "source": [
    "# ðŸš€ Customize and Deploy `microsoft/Florence-2-large` on Amazon SageMaker AI\n",
    "---\n",
    "In this notebook, we explore **Florence-2-large**, Microsoft's advanced vision-language model that excels at understanding and generating content from both images and text. You'll learn how to fine-tune it on multimodal datasets, evaluate its vision capabilities, and deploy it using SageMaker.\n",
    "\n",
    "**What is Florence-2-large?**\n",
    "\n",
    "Microsoft's **Florence-2-large** is a state-of-the-art vision-language model that can process both images and text to perform a wide variety of computer vision and multimodal tasks. From image captioning and visual question answering to object detection and OCR, Florence-2-large provides a unified approach to vision-language understanding.  \n",
    "ðŸ”— Model card: [microsoft/Florence-2-large on Hugging Face](https://huggingface.co/microsoft/Florence-2-large)\n",
    "\n",
    "---\n",
    "\n",
    "**Key Specifications**\n",
    "\n",
    "| Feature | Details |\n",
    "|---|---|\n",
    "| **Parameters** | ~770 million |\n",
    "| **Architecture** | Vision Transformer + Language Model with cross-modal attention |\n",
    "| **Modalities** | Image + Text input â†’ Text output |\n",
    "| **Vision Encoder** | Advanced vision transformer for image understanding |\n",
    "| **Tasks Supported** | Captioning, VQA, OCR, Object Detection, Segmentation |\n",
    "| **License** | MIT License |\n",
    "| **Image Resolution** | High-resolution image processing capabilities |\n",
    "\n",
    "---\n",
    "\n",
    "**Benchmarks & Behavior**\n",
    "\n",
    "- Florence-2-large achieves **state-of-the-art performance** on numerous vision-language benchmarks.  \n",
    "- Excellent **image understanding** with detailed scene analysis and object recognition.  \n",
    "- Strong **OCR capabilities** for text extraction from images and documents.  \n",
    "- Versatile **multimodal reasoning** combining visual and textual information effectively.  \n",
    "\n",
    "---\n",
    "\n",
    "**Using This Notebook**\n",
    "\n",
    "Here's what you'll cover:\n",
    "\n",
    "* Load multimodal datasets and prepare them for vision-language fine-tuning  \n",
    "* Fine-tune with SageMaker Training Jobs using vision-optimized configurations  \n",
    "* Run Model Evaluation on vision-language benchmarks  \n",
    "* Deploy to SageMaker Endpoints for multimodal inference  \n",
    "\n",
    "---\n",
    "\n",
    "Let's begin by exploring `microsoft/Florence-2-large` and testing its vision-language capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce40054-610a-4acc-a546-943893f293c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -Uq sagemaker datasets pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b791e72e-82b5-4f8e-a7fe-700e8afdeba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c673a9-5b9f-47e0-92cf-bb97486b3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "\n",
    "sess = sagemaker.Session(boto3.Session(region_name=region))\n",
    "\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9786901-b012-41ff-a98a-b16e5f60ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}